"use strict";
var __createBinding = (this && this.__createBinding) || (Object.create ? (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    var desc = Object.getOwnPropertyDescriptor(m, k);
    if (!desc || ("get" in desc ? !m.__esModule : desc.writable || desc.configurable)) {
      desc = { enumerable: true, get: function() { return m[k]; } };
    }
    Object.defineProperty(o, k2, desc);
}) : (function(o, m, k, k2) {
    if (k2 === undefined) k2 = k;
    o[k2] = m[k];
}));
var __setModuleDefault = (this && this.__setModuleDefault) || (Object.create ? (function(o, v) {
    Object.defineProperty(o, "default", { enumerable: true, value: v });
}) : function(o, v) {
    o["default"] = v;
});
var __importStar = (this && this.__importStar) || function (mod) {
    if (mod && mod.__esModule) return mod;
    var result = {};
    if (mod != null) for (var k in mod) if (k !== "default" && Object.prototype.hasOwnProperty.call(mod, k)) __createBinding(result, mod, k);
    __setModuleDefault(result, mod);
    return result;
};
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.Fetcher = void 0;
exports.readFile = readFile;
exports.readFileSync = readFileSync;
exports.readFileAndWarn = readFileAndWarn;
exports.readJsonSync = readJsonSync;
exports.readJson = readJson;
exports.tryReadJson = tryReadJson;
exports.writeFile = writeFile;
exports.writeJson = writeJson;
exports.streamOfString = streamOfString;
exports.stringOfStream = stringOfStream;
exports.streamDone = streamDone;
exports.makeHttpRequest = makeHttpRequest;
exports.isDirectory = isDirectory;
exports.downloadAndExtractFile = downloadAndExtractFile;
exports.streamToBuffer = streamToBuffer;
exports.gzip = gzip;
exports.unGzip = unGzip;
exports.writeTgz = writeTgz;
exports.createTgz = createTgz;
exports.createGitHubStringSetGetter = createGitHubStringSetGetter;
const fs_1 = __importDefault(require("fs"));
const tar_1 = require("tar");
const tar_stream_1 = __importDefault(require("tar-stream"));
const https_1 = __importStar(require("https"));
const path_1 = require("path");
const zlib_1 = __importDefault(require("zlib"));
const http_1 = require("http");
const stream_1 = require("stream");
const string_decoder_1 = require("string_decoder");
const miscellany_1 = require("./miscellany");
const fs_2 = require("./fs");
const assertions_1 = require("./assertions");
const promises_1 = require("stream/promises");
async function readFile(path) {
    const res = await fs_1.default.promises.readFile(path, { encoding: "utf8" });
    if (res.includes("�")) {
        throw new Error(`Bad character in ${path}`);
    }
    return res;
}
function readFileSync(path) {
    const res = fs_1.default.readFileSync(path, { encoding: "utf8" });
    if (res.includes("�")) {
        throw new Error(`Bad character in ${path}`);
    }
    return res;
}
/** If a file doesn't exist, warn and tell the step it should have been generated by. */
async function readFileAndWarn(generatedBy, filePath) {
    try {
        return await readJson(filePath, miscellany_1.isObject);
    }
    catch (e) {
        console.error(`Run ${generatedBy} first!`);
        throw e;
    }
}
function readJsonSync(path, predicate) {
    return (0, miscellany_1.parseJson)(readFileSync(path), predicate);
}
async function readJson(path, predicate) {
    return (0, miscellany_1.parseJson)(await readFile(path), predicate);
}
async function tryReadJson(path, predicate) {
    return (0, miscellany_1.tryParseJson)(await readFile(path), predicate);
}
function writeFile(path, content) {
    return fs_1.default.promises.writeFile(path, content, { encoding: "utf8" });
}
function writeJson(path, content, formatted = true) {
    return fs_1.default.promises.writeFile(path, JSON.stringify(content, undefined, formatted ? 4 : undefined));
}
function streamOfString(text) {
    const s = new stream_1.Readable();
    s.push(text);
    s.push(null);
    return s;
}
function stringOfStream(stream, description) {
    const decoder = new string_decoder_1.StringDecoder("utf8");
    let body = "";
    stream.on("data", (data) => {
        body += decoder.write(data);
    });
    return new Promise((resolve, reject) => {
        stream.on("error", reject);
        stream.on("end", () => {
            body += decoder.end();
            if (body.includes("�")) {
                reject(`Bad character decode in ${description}`);
            }
            else {
                resolve(body);
            }
        });
    });
}
function streamDone(stream) {
    return new Promise((resolve, reject) => {
        stream.on("error", reject).on("finish", resolve);
    });
}
class Fetcher {
    agent = new https_1.Agent({ keepAlive: true });
    async fetchJson(options) {
        const text = await this.fetch(options);
        try {
            return JSON.parse(text);
        }
        catch (e) {
            throw new Error(`Bad response from server:\noptions: ${JSON.stringify(options)}\n\n${text}`);
        }
    }
    async fetch(options) {
        const maxRetries = options.retries === false || options.retries === undefined ? 0 : options.retries === true ? 10 : options.retries;
        for (let retries = maxRetries; retries > 1; retries--) {
            try {
                return await doRequest(options, https_1.request, this.agent);
            }
            catch (err) {
                if (!/EAI_AGAIN|ETIMEDOUT|ECONNRESET/.test(err.message)) {
                    throw err;
                }
            }
            await (0, miscellany_1.sleep)(1);
        }
        return doRequest(options, https_1.request, this.agent);
    }
}
exports.Fetcher = Fetcher;
/** Only used for testing. */
function makeHttpRequest(options) {
    return doRequest(options, http_1.request);
}
function doRequest(options, makeRequest, agent) {
    return new Promise((resolve, reject) => {
        const req = makeRequest({
            hostname: options.hostname,
            port: options.port,
            path: `/${options.path}`,
            agent,
            method: options.method || "GET",
            headers: options.headers,
            timeout: options.timeout ?? downloadTimeout,
        }, (res) => {
            let text = "";
            res.on("data", (d) => {
                text += d;
            });
            res.on("error", reject);
            res.on("end", () => {
                resolve(text);
            });
        });
        if (options.body !== undefined) {
            req.write(options.body);
        }
        req.end();
    });
}
async function isDirectory(path) {
    return (await fs_1.default.promises.stat(path)).isDirectory();
}
const downloadTimeout = 1_000_000; // ms
const connectionTimeout = 800_000; // ms
function downloadAndExtractFile(url, log) {
    return new Promise((resolve, reject) => {
        const timeout = setTimeout(reject, downloadTimeout);
        function rejectAndClearTimeout(reason) {
            clearTimeout(timeout);
            return reject(reason);
        }
        const root = new fs_2.Dir(undefined);
        function insertFile(path, content) {
            const components = path.split("/");
            const baseName = (0, assertions_1.assertDefined)(components.pop());
            let dir = root;
            for (const component of components) {
                dir = dir.subdir(component);
            }
            dir.set(baseName, content);
        }
        log.info("Requesting " + url);
        https_1.default
            .get(url, { timeout: connectionTimeout }, (response) => {
            if (response.statusCode !== 200) {
                return rejectAndClearTimeout(new Error(`DefinitelyTyped download failed with status code ${response.statusCode}`));
            }
            log.info("Getting " + url);
            const extract = tar_stream_1.default.extract();
            extract.on("entry", (header, stream, next) => {
                const name = (0, assertions_1.assertDefined)((0, miscellany_1.withoutStart)(header.name, "DefinitelyTyped-master/"));
                switch (header.type) {
                    case "file":
                        stringOfStream(stream, name)
                            .then((s) => {
                            insertFile(name, s);
                            next();
                        })
                            .catch(rejectAndClearTimeout);
                        break;
                    case "directory":
                        next();
                        break;
                    default:
                        throw new Error(`Unexpected file system entry kind ${header.type}`);
                }
            });
            extract.on("error", rejectAndClearTimeout);
            extract.on("finish", () => {
                log.info("Done receiving " + url);
                clearTimeout(timeout);
                resolve(new fs_2.InMemoryFS(root.finish(), "/"));
            });
            response.pipe(zlib_1.default.createGunzip()).pipe(extract);
        })
            .on("error", rejectAndClearTimeout);
    });
}
async function streamToBuffer(stream) {
    const chunks = [];
    await (0, promises_1.pipeline)(stream, async (source) => {
        for await (const chunk of source) {
            chunks.push(Buffer.from(chunk));
        }
    });
    return Buffer.concat(chunks);
}
function gzip(input) {
    return input.pipe(zlib_1.default.createGzip());
}
function unGzip(input) {
    const output = zlib_1.default.createGunzip();
    input.pipe(output);
    return output;
}
function writeTgz(inputDirectory, outFileName) {
    return new Promise((resolve, reject) => {
        resolve(streamDone(createTgz(inputDirectory, reject).pipe(fs_1.default.createWriteStream(outFileName))));
    });
}
// To output this for testing:
// `require("./dist/io").createTgz("./src", err => { throw err }).pipe(fs.createWriteStream("foo.tgz"))`
function createTgz(dir, onError) {
    return gzip(createTar(dir, onError));
}
function createTar(dir, onError) {
    const dirSegments = (0, path_1.resolve)(dir).split(path_1.sep);
    const parentDir = dirSegments.slice(0, dirSegments.length - 1).join(path_1.sep);
    const entryToAdd = dirSegments[dirSegments.length - 1];
    const packer = new tar_1.Pack({ cwd: parentDir, filter: addDirectoryExecutablePermission });
    packer.on("error", onError);
    const stream = packer.add(entryToAdd);
    packer.end();
    // Shady, but minipass is compatible enough with ReadableStream for this use.
    return stream;
}
/**
 * Work around a bug where directories bundled on Windows do not have executable permission when extracted on Linux.
 * https://github.com/npm/node-tar/issues/7#issuecomment-17572926
 */
function addDirectoryExecutablePermission(_, stat) {
    if (stat.isDirectory()) {
        stat.mode = addExecutePermissionsFromReadPermissions(stat.mode);
    }
    return true;
}
function addExecutePermissionsFromReadPermissions(mode) {
    // Constant that gives execute permissions to owner, group, and others. "+x"
    const allExecutePermissions = 0o111;
    // Moves the bits for read permissions into the place for execute permissions.
    // In other words, a component will have execute permissions if it has read permissions.
    const readPermissionsAsExecutePermissions = (mode >>> 2) & allExecutePermissions;
    // Add these additional execute permissions to the mode.
    return mode | readPermissionsAsExecutePermissions;
}
function getUrlContentsAsString(url) {
    return new Promise((resolve, reject) => {
        https_1.default
            .get(url, (res) => {
            let data = "";
            res.on("data", (d) => (data += d));
            res.on("end", () => {
                resolve(data);
            });
        })
            .on("error", reject);
    });
}
function withCache(expiresInMs, getValue) {
    let value;
    let resolvedAt;
    return async () => {
        if (resolvedAt === undefined || Date.now() - resolvedAt > expiresInMs) {
            value = await getValue();
            resolvedAt = Date.now();
        }
        return value;
    };
}
function createGitHubStringSetGetter(repoPath, fallbackPath) {
    const url = `https://raw.githubusercontent.com/microsoft/DefinitelyTyped-tools/main/${repoPath}`;
    return withCache(60 * 60 * 1000, async () => {
        let raw = readFileSync(fallbackPath);
        if (process.env.NODE_ENV !== "test") {
            try {
                raw = await getUrlContentsAsString(url);
            }
            catch (err) {
                console.error(`Getting the latest ${repoPath} from GitHub failed. Falling back to local copy.\n` + err.message);
            }
        }
        return new Set(raw.split(/\r?\n/));
    });
}
//# sourceMappingURL=io.js.map